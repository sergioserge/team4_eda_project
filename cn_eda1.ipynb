{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define Excel File Constant, and import function\n",
    "\n",
    "EXCEL_FILE = \"data/Muesli Project raw data 21-3.xlsx\"\n",
    "\n",
    "def import_xls(file, sheet, header=0):\n",
    "    df = pd.read_excel(file, sheet_name = sheet, header=header)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Excel Sheets as separate DFs\n",
    "\n",
    "df_orders = import_xls(EXCEL_FILE, \"Orders\", header=1)\n",
    "df_order_process = import_xls(EXCEL_FILE, \"Order Process Data\")\n",
    "df_intern = import_xls(EXCEL_FILE, \"InternData Study\")\n",
    "df_campaign = import_xls(EXCEL_FILE, \"Campaign Data\")\n",
    "df_list = [df_orders, df_order_process, df_intern, df_campaign]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Column Renaming Function\n",
    "def column_rename(df):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>origin_channel</th>\n",
       "      <th>country/region</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>region</th>\n",
       "      <th>category</th>\n",
       "      <th>sub-category</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2017-103800</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>DP-13000</td>\n",
       "      <td>Darren Powers</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>77095.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Power Muesli</td>\n",
       "      <td>Nuts and more</td>\n",
       "      <td>OFF-PA-10000174</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2017-112326</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>PO-19195</td>\n",
       "      <td>Phillina Ober</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>United States</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>60540.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Power Muesli</td>\n",
       "      <td>No Taste All Power</td>\n",
       "      <td>OFF-LA-10003223</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-2017-141817</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>MB-18085</td>\n",
       "      <td>Mick Brown</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>19143.0</td>\n",
       "      <td>East</td>\n",
       "      <td>Power Muesli</td>\n",
       "      <td>Super Mega Protein</td>\n",
       "      <td>OFF-AR-10003478</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA-2017-106054</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>JO-15145</td>\n",
       "      <td>Jack O'Briant</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>30605.0</td>\n",
       "      <td>South</td>\n",
       "      <td>Power Muesli</td>\n",
       "      <td>Super Mega Protein</td>\n",
       "      <td>OFF-AR-10002399</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CA-2017-130813</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>LS-17230</td>\n",
       "      <td>Lycoris Saunders</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>West</td>\n",
       "      <td>Power Muesli</td>\n",
       "      <td>Nuts and more</td>\n",
       "      <td>OFF-PA-10002005</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id order_date customer_id     customer_name origin_channel  \\\n",
       "0  CA-2017-103800 2017-01-03    DP-13000     Darren Powers          Email   \n",
       "1  CA-2017-112326 2017-01-04    PO-19195     Phillina Ober       Facebook   \n",
       "4  CA-2017-141817 2017-01-05    MB-18085        Mick Brown          Email   \n",
       "5  CA-2017-106054 2017-01-06    JO-15145     Jack O'Briant          Sales   \n",
       "6  CA-2017-130813 2017-01-06    LS-17230  Lycoris Saunders          Email   \n",
       "\n",
       "  country/region          city         state  postal_code   region  \\\n",
       "0  United States       Houston         Texas      77095.0  Central   \n",
       "1  United States    Naperville      Illinois      60540.0  Central   \n",
       "4  United States  Philadelphia  Pennsylvania      19143.0     East   \n",
       "5  United States        Athens       Georgia      30605.0    South   \n",
       "6  United States   Los Angeles    California      90049.0     West   \n",
       "\n",
       "       category        sub-category       product_id  quantity  \n",
       "0  Power Muesli       Nuts and more  OFF-PA-10000174       2.0  \n",
       "1  Power Muesli  No Taste All Power  OFF-LA-10003223       3.0  \n",
       "4  Power Muesli  Super Mega Protein  OFF-AR-10003478       3.0  \n",
       "5  Power Muesli  Super Mega Protein  OFF-AR-10002399       3.0  \n",
       "6  Power Muesli       Nuts and more  OFF-PA-10002005       3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename all DF columns\n",
    "for df in df_list:\n",
    "    column_rename(df)\n",
    "#display(df_orders.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " Total order_id count is 5009\n",
      " Total unique order_id count is 5009\n",
      "1\n",
      " Total order_id count is 3002\n",
      " Total unique order_id count is 3002\n",
      "2\n",
      " Total order_id count is 204\n",
      " Total unique order_id count is 204\n",
      "3\n",
      " Total order_id count is 333\n",
      " Total unique order_id count is 333\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "for idx, df in enumerate(df_list):\n",
    "    print(idx)\n",
    "    print(f\" Total order_id count is {df['order_id'].count()}\")\n",
    "    print(f\" Total unique order_id count is {df['order_id'].nunique()}\")\n",
    "# 0 df_orders, 1 df_order_process, 2 df_intern, 3 df_campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define duplicate row removal on order_id function  \n",
    "def duplicate_id_removal(df):\n",
    "    df.drop_duplicates(subset=['order_id'], inplace=True)\n",
    "    df.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates for all DFs\n",
    "for df in df_list:\n",
    "     duplicate_id_removal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have all the order ids in the order process dataset. \n",
      "Contrary to company assumptions there is a difference of 2007 untracked orders\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3002 entries, 4095 to 9993\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   order_id        3002 non-null   object        \n",
      " 1   order_date      3002 non-null   datetime64[ns]\n",
      " 2   customer_id     3002 non-null   object        \n",
      " 3   customer_name   3002 non-null   object        \n",
      " 4   origin_channel  3002 non-null   object        \n",
      " 5   country/region  3002 non-null   object        \n",
      " 6   city            3002 non-null   object        \n",
      " 7   state           3002 non-null   object        \n",
      " 8   postal_code     2998 non-null   float64       \n",
      " 9   region          3002 non-null   object        \n",
      " 10  category        3002 non-null   object        \n",
      " 11  sub-category    3002 non-null   object        \n",
      " 12  product_id      3002 non-null   object        \n",
      " 13  quantity        3002 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 351.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3002 entries, 0 to 3002\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   order_id            3002 non-null   object        \n",
      " 1   order_date          3002 non-null   datetime64[ns]\n",
      " 2   on_truck_scan_date  3002 non-null   datetime64[ns]\n",
      " 3   processing_mode     3002 non-null   object        \n",
      "dtypes: datetime64[ns](2), object(2)\n",
      "memory usage: 181.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See if assumption about all order IDs being included in the order process tracking is correct\n",
    "num_unique_dif = df_orders['order_id'].count() - df_order_process['order_id'].count()\n",
    "print(f\"We don't have all the order ids in the order process dataset. \\nContrary to company assumptions there is a difference of {num_unique_dif} untracked orders\")\n",
    "\n",
    "# Investigate if all orders from 2/1/2019 on are tracked then\n",
    "\n",
    "df_orders_recent = df_orders[df_orders['order_date'] >= df_order_process[\"order_date\"][0]]\n",
    "display(df_orders_recent.info())\n",
    "display(df_order_process.info())\n",
    "\n",
    "\n",
    "# df_orders['order_id'].isin(df_order_process['order_id']).count()\n",
    "# ~ = not in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>origin_channel</th>\n",
       "      <th>country/region</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>on_truck_scan_date</th>\n",
       "      <th>processing_mode</th>\n",
       "      <th>order_id</th>\n",
       "      <th>ready_to_ship_date</th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>order_id</th>\n",
       "      <th>arrival_scan_date</th>\n",
       "      <th>customer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CA-2019-160304</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "      <td>CA-2019-116540</td>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>CA-2019-109666</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>Kunst Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CA-2019-125206</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Express</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CA-2019-138933</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>Jack Lebron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>US-2019-116365</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "      <td>CA-2019-129847</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>CA-2019-130001</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>Heather Kirkland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>CA-2019-105207</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "      <td>CA-2019-129630</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>CA-2019-113061</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>Ed Ludwig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>US-2019-164630</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>Standard Processing</td>\n",
       "      <td>CA-2019-106278</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>CA-2019-162138</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>Grace Kelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>US-2020-158526</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>KH-16360</td>\n",
       "      <td>Katherine Hughes</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>40214.0</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>CA-2020-115427</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>EB-13975</td>\n",
       "      <td>Erica Bern</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>California</td>\n",
       "      <td>94533.0</td>\n",
       "      <td>West</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>CA-2020-126221</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>CC-12430</td>\n",
       "      <td>Chuck Clark</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>United States</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>47201.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>CA-2020-143259</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>PO-18865</td>\n",
       "      <td>Patrick O'Donnell</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>East</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>CA-2020-156720</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>JM-15580</td>\n",
       "      <td>Jill Matthias</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Loveland</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>80538.0</td>\n",
       "      <td>West</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6004 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id order_date customer_id      customer_name origin_channel  \\\n",
       "0                NaN        NaT         NaN                NaN            NaN   \n",
       "1                NaN        NaT         NaN                NaN            NaN   \n",
       "2                NaN        NaT         NaN                NaN            NaN   \n",
       "3                NaN        NaT         NaN                NaN            NaN   \n",
       "4                NaN        NaT         NaN                NaN            NaN   \n",
       "...              ...        ...         ...                ...            ...   \n",
       "9982  US-2020-158526 2020-12-29    KH-16360   Katherine Hughes          Email   \n",
       "9987  CA-2020-115427 2020-12-30    EB-13975         Erica Bern          Sales   \n",
       "9989  CA-2020-126221 2020-12-30    CC-12430        Chuck Clark       Facebook   \n",
       "9990  CA-2020-143259 2020-12-30    PO-18865  Patrick O'Donnell          Email   \n",
       "9993  CA-2020-156720 2020-12-30    JM-15580      Jill Matthias          Email   \n",
       "\n",
       "     country/region           city       state  postal_code   region  ...  \\\n",
       "0               NaN            NaN         NaN          NaN      NaN  ...   \n",
       "1               NaN            NaN         NaN          NaN      NaN  ...   \n",
       "2               NaN            NaN         NaN          NaN      NaN  ...   \n",
       "3               NaN            NaN         NaN          NaN      NaN  ...   \n",
       "4               NaN            NaN         NaN          NaN      NaN  ...   \n",
       "...             ...            ...         ...          ...      ...  ...   \n",
       "9982  United States     Louisville    Kentucky      40214.0    South  ...   \n",
       "9987  United States      Fairfield  California      94533.0     West  ...   \n",
       "9989  United States       Columbus     Indiana      47201.0  Central  ...   \n",
       "9990  United States  New York City    New York      10009.0     East  ...   \n",
       "9993  United States       Loveland    Colorado      80538.0     West  ...   \n",
       "\n",
       "            order_id order_date on_truck_scan_date      processing_mode  \\\n",
       "0     CA-2019-160304 2019-01-02         2019-01-09  Standard Processing   \n",
       "1     CA-2019-125206 2019-01-03         2019-01-07              Express   \n",
       "2     US-2019-116365 2019-01-03         2019-01-09  Standard Processing   \n",
       "3     CA-2019-105207 2019-01-03         2019-01-09  Standard Processing   \n",
       "4     US-2019-164630 2019-01-04         2019-01-11  Standard Processing   \n",
       "...              ...        ...                ...                  ...   \n",
       "9982             NaN        NaT                NaT                  NaN   \n",
       "9987             NaN        NaT                NaT                  NaN   \n",
       "9989             NaN        NaT                NaT                  NaN   \n",
       "9990             NaN        NaT                NaT                  NaN   \n",
       "9993             NaN        NaT                NaT                  NaN   \n",
       "\n",
       "            order_id ready_to_ship_date pickup_date        order_id  \\\n",
       "0     CA-2019-116540         2019-09-02  2019-09-03  CA-2019-109666   \n",
       "1                NaN                NaT         NaT  CA-2019-138933   \n",
       "2     CA-2019-129847         2019-09-04  2019-09-04  CA-2019-130001   \n",
       "3     CA-2019-129630         2019-09-04  2019-09-04  CA-2019-113061   \n",
       "4     CA-2019-106278         2019-09-05  2019-09-06  CA-2019-162138   \n",
       "...              ...                ...         ...             ...   \n",
       "9982             NaN                NaT         NaT             NaN   \n",
       "9987             NaN                NaT         NaT             NaN   \n",
       "9989             NaN                NaT         NaT             NaN   \n",
       "9990             NaN                NaT         NaT             NaN   \n",
       "9993             NaN                NaT         NaT             NaN   \n",
       "\n",
       "     arrival_scan_date     customer_name  \n",
       "0           2019-05-03      Kunst Miller  \n",
       "1           2019-05-03       Jack Lebron  \n",
       "2           2019-05-03  Heather Kirkland  \n",
       "3           2019-05-06         Ed Ludwig  \n",
       "4           2019-05-06       Grace Kelly  \n",
       "...                ...               ...  \n",
       "9982               NaT               NaN  \n",
       "9987               NaT               NaN  \n",
       "9989               NaT               NaN  \n",
       "9990               NaT               NaN  \n",
       "9993               NaT               NaN  \n",
       "\n",
       "[6004 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_list = [df_orders, df_order_process, df_intern, df_campaign]\n",
    "\n",
    "df_all = pd.merge(df_orders, df_order_process, how='left', on='order_id')\n",
    "df_all = pd.merge(df_all, df_intern, how='left', on='order_id')\n",
    "df_all = pd.merge(df_all, df_campaign, how='left', on='order_id')\n",
    "\n",
    "df = pd.merge(df_orders, df_order_process, how='inner', on='order_id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublecheck if we have the same amount of unique order ids in merged df as in the df_order_process\n",
    "display(df['order_id'].nunique())\n",
    "\n",
    "display(df_all.head())\n",
    "display(df.head())\n",
    "\n",
    "display(df_all.info())\n",
    "display(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"order_id\"].nunique()\n",
    "drop_list = ['customer_name', 'country/region', 'city', 'state', 'postal_code', 'region'] \n",
    "df = df.drop(drop_list, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"order_date_x\"] != df[\"order_date_y\"]]\n",
    "df[df[\"order_date_x\"] == df[\"order_date_y\"]].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"order_date_y\", axis=1, inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"order_date_x\": \"order_date\"}, inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pretransportation_duration\"] = df[\"on_truck_scan_date\"] - df[\"order_date\"]\n",
    "df[\"pretransportation_duration\"] = df[\"pretransportation_duration\"].dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['order_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two labels of delivery date depending on express/ non/express processing(see flowchart)\n",
    "same_arrival_day = [0, 2, 5, 6]\n",
    "different_arrival_day = [1, 3, 4]\n",
    "\n",
    "# Devide the dataframe into two groups with regard to these labels\n",
    "same_day = df[df['weekday'].isin(same_arrival_day)]\n",
    "different_days = df[df['weekday'].isin(different_arrival_day)]\n",
    "\n",
    "# Doublecheck if the division is done correctly\n",
    "check_difference = df['order_id'].count() - same_day['order_id'].count() - different_days['order_id'].count()\n",
    "display(f'The Difference should be zero: ', check_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare descriptive statistics of each dataset\n",
    "display('Same Day' ,same_day.describe())\n",
    "display('Different Day' ,different_days.describe())\n",
    "\n",
    "# Comparison:\n",
    "# quantities: shows very equal distribution, though same_day orders are from 4 days and different days are from 3\n",
    " # Tuesday, Thursday and Friday are days with a lot of incoming orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should analyse and visualize the days with the most incoming orders\n",
    "# e.g. Barchart of orderquantities and weekdays\n",
    "\n",
    "\n",
    "# Combine pretransportation_duration with standard_processing-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Delivery Time Assumption (average 3 days)\n",
    "# Create merged df and campaign DF\n",
    "campaign_merged = pd.merge(df, df_campaign , how='inner', on='order_id')\n",
    "\n",
    "#Split into truck leaving the same day as the order and truck leaving on a different day\n",
    "matched_different_days = campaign_merged[campaign_merged['weekday'].isin(different_arrival_day)].reset_index().drop(\"index\", axis=1)\n",
    "matched_same_day = campaign_merged[campaign_merged['weekday'].isin(same_arrival_day)].reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "#Create new column for delivery duration for both DFs\n",
    "matched_different_days[\"delivery_duration\"] = matched_different_days[\"arrival_scan_date\"] - matched_different_days[\"on_truck_scan_date\"]\n",
    "matched_same_day[\"delivery_duration\"] = matched_same_day[\"arrival_scan_date\"] - matched_same_day[\"on_truck_scan_date\"]\n",
    "\n",
    "#Simple Analysis on the two DFs\n",
    "display(matched_different_days.describe())\n",
    "display(matched_same_day.describe())\n",
    "\n",
    "#Groupby weekday of truck scan\n",
    "\n",
    "# Create new column for on truck scan weekday\n",
    "campaign_merged['weekday_scan'] = campaign_merged['on_truck_scan_date'].dt.weekday\n",
    "# Create new column for delivery duration\n",
    "campaign_merged['delivery_duration'] = campaign_merged[\"arrival_scan_date\"] - campaign_merged[\"on_truck_scan_date\"]\n",
    "campaign_merged['delivery_duration'].dt.days\n",
    "# Create new column for total duration\n",
    "campaign_merged['total_duration'] = campaign_merged[\"arrival_scan_date\"] - campaign_merged[\"order_date\"]\n",
    "campaign_merged['delivery_duration'].dt.days\n",
    "\n",
    "# Drop irrelevant columns\n",
    "campaign_merged.drop(['quantity', 'weekday'], axis=1, inplace=True)\n",
    "display(campaign_merged.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupy on truck weekday\n",
    "display(campaign_merged)\n",
    "groupby = campaign_merged.groupby(by=\"weekday_scan\")\n",
    "groupby.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI:\n",
    "# Company Level\n",
    "# Average delivery duration (standard): now --> goal\n",
    "# Average delivery duration (express): now --> goal\n",
    "# --> stacked barchart from order to warehouse to delivery(process issues not relevant)\n",
    "\n",
    "# Processing Level\n",
    "# Average processing duration (standard): now --> goal\n",
    "# Average processing duration (express): now --> goal \n",
    "# --> visualization (process issues not relevant, besides delivery)\n",
    "\n",
    "# Warehouse Level\n",
    "# Average warehouse duration (standard): now --> goal\n",
    "# Average warehouse duration (express): now --> goal \n",
    "# --> visualization (all process issues are relevant) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "839aa98f85fe47239cd00cf3d96744c3476cb0937cd6117bf226de5974f25a30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('eda_project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
